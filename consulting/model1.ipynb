{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - Part 1\n",
    "### What we learnt from correlation matrix:\n",
    "- Maybe not for a linear model\n",
    "- price-related columns, power&energy-consumption-related columns are correlated\n",
    "- How will imbalance data influence modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'cons_12m', 'cons_gas_12m', 'cons_last_month',\n",
       "       'cons_last_month.1', 'forecast_cons_12m', 'forecast_cons_year',\n",
       "       'forecast_discount_energy', 'forecast_meter_rent_12m',\n",
       "       'forecast_price_energy_p1', 'forecast_price_energy_p2',\n",
       "       'forecast_price_pow_p1', 'has_gas', 'imp_cons', 'margin_gross_pow_ele',\n",
       "       'margin_net_pow_ele', 'nb_prod_act', 'net_margin', 'num_years_antig',\n",
       "       'pow_max', 'channel0', 'channel1', 'channel2', 'channel3', 'channel4',\n",
       "       'channel5', 'channel6', 'days_activ', 'days_end', 'days_modif',\n",
       "       'days_renewal', 'origin0', 'origin1', 'origin2', 'origin3', 'origin4',\n",
       "       'prices_p1_var', 'prices_p2_var', 'prices_p3_var', 'prices_p1_fix',\n",
       "       'prices_p2_fix', 'prices_p3_fix', 'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('./all.csv')\n",
    "cols = train_df.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.　Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC score:  0.63723398816\n",
      "Brier score:  0.0857957663748\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# We don't need ids here so just drop it for a while\n",
    "ids = list(train_df.id)\n",
    "train_lr = train_df.drop(['id'], axis=1)\n",
    "\n",
    "# scale the data to (0,1)\n",
    "for col in list(train_lr.columns[:-1]):\n",
    "    temp = list(train_lr[col])\n",
    "    temp = [float(x) for x in temp]\n",
    "    max_val = max(temp)\n",
    "    train_lr[col] = [x / max_val for x in temp]\n",
    "    \n",
    "X = train_lr.drop(['churn'], axis=1).as_matrix()\n",
    "y = train_lr['churn'].as_matrix()\n",
    "\n",
    "# Now train our LR model using Leave-One-Out cross validation\n",
    "lr = LogisticRegression()\n",
    "y_pred = cross_val_predict(lr, X, y, cv=5, method='predict_proba')\n",
    "y_positive_pred = [x[1] for x in y_pred]\n",
    "\n",
    "auroc_lr = roc_auc_score(y, y_positive_pred)\n",
    "brier_lr = brier_score_loss(y, y_positive_pred)\n",
    "\n",
    "print ('AUROC score: ', auroc_lr)\n",
    "print ('Brier score: ', brier_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.　Linear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC score:  0.542053111265\n",
      "Brier score:  0.0874521740319\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# We don't need ids here so just drop it for a while\n",
    "ids = list(train_df.id)\n",
    "train_svm = train_df.drop(['id'], axis=1)\n",
    "\n",
    "# scale the data to (0,1)\n",
    "for col in list(train_svm.columns[:-1]):\n",
    "    temp = list(train_svm[col])\n",
    "    temp = [float(x) for x in temp]\n",
    "    max_val = max(temp)\n",
    "    train_svm[col] = [x / max_val for x in temp]\n",
    "    \n",
    "X = train_svm.drop(['churn'], axis=1).as_matrix()\n",
    "y = train_svm['churn'].as_matrix()\n",
    "\n",
    "# Now train our SVMs model using Leave-One-Out cross validation\n",
    "svc = SVC(kernel='linear', probability=True)\n",
    "y_pred = cross_val_predict(svc, X, y, cv=5, method='predict_proba')\n",
    "y_positive_pred = [x[1] for x in y_pred]\n",
    "\n",
    "auroc_svm = roc_auc_score(y, y_positive_pred)\n",
    "brier_svm = brier_score_loss(y, y_positive_pred)\n",
    "\n",
    "print ('AUROC score: ', auroc_svm)\n",
    "print ('Brier score: ', brier_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.　Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# We don't need ids here so just drop it for a while\n",
    "ids = list(train_df.id)\n",
    "train_rf = train_df.drop(['id'], axis=1)\n",
    "\n",
    "X = train_rf.drop(['churn'], axis=1).as_matrix()\n",
    "y = train_rf['churn'].as_matrix()\n",
    "\n",
    "# Grid search parameters for random forest classifier\n",
    "params = []\n",
    "for n_trees in [10, 20, 50]:\n",
    "    for max_feature in ['sqrt', 'log2', None]:\n",
    "        for max_depth in [2, 5, 10, None]:\n",
    "            for min_smp in [1, 5, 10]:\n",
    "                for balanced in ['balanced', None]:\n",
    "                    params.append([n_trees, max_feature, max_depth, min_smp, balanced])\n",
    "\n",
    "results_dict = {'params' : [], 'auroc': [], 'brier': []}\n",
    "\n",
    "# Now train our grid search classifiers\n",
    "def parallel_learner(param):\n",
    "    rf = RandomForestClassifier(n_estimators=param[0], \\\n",
    "                                max_features=param[1], \\\n",
    "                                max_depth=param[2], \\\n",
    "                                min_samples_leaf=param[3], \\\n",
    "                                class_weight=param[4], \\\n",
    "                                n_jobs=8)\n",
    "    loo = LeaveOneOut()\n",
    "    y_pred = cross_val_predict(rf, X, y, cv=5, method='predict_proba')\n",
    "    y_positive_pred = [x[1] for x in y_pred]\n",
    "    \n",
    "    auroc_rf = roc_auc_score(y, y_positive_pred)\n",
    "    brier_rf = brier_score_loss(y, y_positive_pred)\n",
    "    \n",
    "    results_dict['params'].append(param)\n",
    "    results_dict['auroc'].append(auroc_rf)\n",
    "    results_dict['brier'].append(brier_rf)\n",
    "    \n",
    "for p in params:\n",
    "    parallel_learner(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 'log2', 10, 5, None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['params'][183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69789495995180828"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['auroc'][183]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.　Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693088502971 0.0814817589464\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# We don't need ids here so just drop it for a while\n",
    "ids = list(train_df.id)\n",
    "train_rf = train_df.drop(['id'], axis=1)\n",
    "\n",
    "X = train_rf.drop(['churn'], axis=1).as_matrix()\n",
    "y = train_rf['churn'].as_matrix()\n",
    "\n",
    "# Now train our grid search classifiers\n",
    "gbm = GradientBoostingClassifier(n_estimators=200)\n",
    "y_pred = cross_val_predict(gbm, X, y, cv=5, method='predict_proba')\n",
    "y_positive_pred = [x[1] for x in y_pred]\n",
    "\n",
    "auroc_rf = roc_auc_score(y, y_positive_pred)\n",
    "brier_rf = brier_score_loss(y, y_positive_pred)\n",
    "\n",
    "print (auroc_rf, brier_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performances are not very good. But our guess about linearity and non-linearity is right. Poor performance may have something to do with imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
